import { NextRequest, NextResponse } from 'next/server'
import { prisma } from '@/lib/prisma'
import { writeFile } from 'fs/promises'
import path from 'path'
import {
  processImage,
  processPDF,
  processWord,
  processExcel,
  processTextFile,
  chunkText,
  ensureDir,
  getFileUrl,
  getFileCategory,
  isAllowedFileType,
  isAllowedFileSize,
} from '@/lib/file-processor'
import { getMemMachineClient } from '@/lib/memmachine-client'
import { optionalAuthenticate } from '@/lib/auth-middleware'

export const runtime = 'nodejs'
export const dynamic = 'force-dynamic'

const MAX_FILE_SIZE = 10 * 1024 * 1024 // 10MB

/**
 * POST /api/files/upload
 * ä¸Šä¼ æ–‡ä»¶
 */
export async function POST(req: NextRequest) {
  try {
    // å¯é€‰è®¤è¯
    const authUser = await optionalAuthenticate(req)
    const userId = authUser?.userId || 'default'

    const formData = await req.formData()

    // è¯¦ç»†æ—¥å¿—ï¼šæŸ¥çœ‹æ¥æ”¶åˆ°çš„ FormData
    console.log('ğŸ“‹ [Upload API] FormData keys:', Array.from(formData.keys()))

    const file = formData.get('file') as File
    const tagsJson = formData.get('tags') as string
    const extractedText = formData.get('extractedText') as string | null  // å®¢æˆ·ç«¯æå–çš„æ–‡æœ¬
    const pdfPages = formData.get('pdfPages') as string | null            // PDF é¡µæ•°

    console.log('ğŸ“‹ [Upload API] File:', file?.name, file?.type, file?.size)
    console.log('ğŸ“‹ [Upload API] extractedText:', extractedText ? `${extractedText.length} chars` : 'null/undefined')
    console.log('ğŸ“‹ [Upload API] pdfPages:', pdfPages || 'null/undefined')

    if (!file) {
      return NextResponse.json(
        { error: 'æ²¡æœ‰æä¾›æ–‡ä»¶' },
        { status: 400 }
      )
    }

    // éªŒè¯æ–‡ä»¶ç±»å‹
    if (!isAllowedFileType(file.type)) {
      return NextResponse.json(
        { error: `ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: ${file.type}` },
        { status: 400 }
      )
    }

    // éªŒè¯æ–‡ä»¶å¤§å°
    if (!isAllowedFileSize(file.size, 10)) {
      return NextResponse.json(
        { error: `æ–‡ä»¶è¿‡å¤§ï¼Œæœ€å¤§æ”¯æŒ 10MB` },
        { status: 400 }
      )
    }

    console.log(`ğŸ“ File upload from user: ${userId}`)
    const fileId = crypto.randomUUID()
    const ext = path.extname(file.name)
    const category = getFileCategory(file.type)

    // ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
    const uploadDir = path.join(process.cwd(), 'public', 'uploads', userId)
    await ensureDir(uploadDir)

    // ä¿å­˜æ–‡ä»¶
    const filename = `${fileId}${ext}`
    const filepath = path.join(uploadDir, filename)
    const arrayBuffer = await file.arrayBuffer()
    await writeFile(filepath, Buffer.from(arrayBuffer))

    console.log(`ğŸ“ File uploaded: ${filename} (${file.size} bytes, ${file.type})`)

    // åˆ›å»ºæ•°æ®åº“è®°å½•
    const fileRecord = await prisma.file.create({
      data: {
        id: fileId,
        filename: file.name,
        filepath: getFileUrl(userId, fileId, ext),
        mimetype: file.type,
        size: file.size,
        userId,
        status: 'processing',
        tags: tagsJson || '[]',
      },
    })

    // åå°å¼‚æ­¥å¤„ç†æ–‡ä»¶ï¼ˆä¸é˜»å¡å“åº”ï¼‰
    processFileAsync(fileId, filepath, file.type, userId, fileRecord.id, extractedText, pdfPages)
      .catch(err => {
        console.error(`âŒ Failed to process file ${fileId}:`, err)
        // æ›´æ–°çŠ¶æ€ä¸ºé”™è¯¯
        prisma.file.update({
          where: { id: fileId },
          data: {
            status: 'error',
            errorMessage: err.message,
          },
        }).catch(console.error)
      })

    // ç«‹å³è¿”å›å“åº”
    return NextResponse.json({
      id: fileRecord.id,
      filename: file.name,
      url: fileRecord.filepath,
      mimetype: file.type,
      size: file.size,
      status: 'processing',
      createdAt: fileRecord.createdAt,
    })

  } catch (error: any) {
    console.error('File upload error:', error)
    return NextResponse.json(
      { error: error.message || 'æ–‡ä»¶ä¸Šä¼ å¤±è´¥' },
      { status: 500 }
    )
  }
}

/**
 * å¼‚æ­¥å¤„ç†æ–‡ä»¶ï¼ˆç”Ÿæˆç¼©ç•¥å›¾ã€æå–æ–‡æœ¬ã€å‘é‡ç´¢å¼•ç­‰ï¼‰
 */
async function processFileAsync(
  fileId: string,
  filepath: string,
  mimetype: string,
  userId: string,
  dbId: string,
  extractedText?: string | null,
  pdfPages?: string | null
) {
  console.log(`ğŸ”„ Processing file ${fileId}...`)

  const category = getFileCategory(mimetype)
  const updateData: any = {}

  // Get user-specific MemMachine client
  const userMemClient = getMemMachineClient(userId)

  try {
    // å¤„ç†å›¾ç‰‡
    if (category === 'image') {
      const uploadDir = path.join(process.cwd(), 'public', 'uploads', userId)
      const imageData = await processImage(filepath, uploadDir, fileId)

      updateData.width = imageData.width
      updateData.height = imageData.height
      updateData.thumbnailPath = imageData.thumbnailPath

      // ç”Ÿæˆå›¾ç‰‡æè¿°
      const filename = path.basename(filepath, path.extname(filepath))
      const description = `å›¾ç‰‡æ–‡ä»¶: ${filename} (${imageData.width}x${imageData.height})`
      updateData.description = description

      // ç´¢å¼•åˆ° MemMachine
      try {
        await userMemClient.addMemory({
          content: `[å›¾ç‰‡æ–‡ä»¶]\næ–‡ä»¶å: ${filename}\nå°ºå¯¸: ${imageData.width}x${imageData.height}\næè¿°: ${description}\nè·¯å¾„: ${filepath}`,
          role: 'user',
          producer: userId,
          produced_for: 'assistant',
          metadata: {
            fileId: dbId,
            type: 'image',
            filename: filename,
            width: imageData.width.toString(),
            height: imageData.height.toString(),
          },
        })
        console.log(`âœ… Image indexed to MemMachine: ${filename}`)
      } catch (err: any) {
        console.error('Failed to index image to MemMachine:', err)
        console.error('Error details:', err.message)
      }

      console.log(`âœ… Image processed: ${fileId}`)
    }

    // å¤„ç† Word æ–‡æ¡£
    if (category === 'word') {
      const wordData = await processWord(filepath)
      updateData.extractedText = wordData.text
      updateData.description = `Word æ–‡æ¡£ï¼Œ${wordData.text.length} å­—ç¬¦`

      const chunks = chunkText(wordData.text)
      console.log(`ğŸ“„ Word processing complete: ${wordData.text.length} chars, ${chunks.length} chunks`)

      await Promise.all(
        chunks.map((content, index) =>
          prisma.fileChunk.create({
            data: {
              fileId: dbId,
              chunkIndex: index,
              content,
            },
          })
        )
      )

      try {
        await userMemClient.addMemories(
          chunks.map((content, index) => ({
            content: `[Wordæ–‡æ¡£: ${path.basename(filepath)} - ç¬¬${index + 1}å—]\n${content}`,
            role: 'user',
            producer: userId,
            produced_for: 'assistant',
            metadata: {
              fileId: dbId,
              chunkIndex: index.toString(),
              type: 'word_chunk',
              filename: path.basename(filepath),
            },
          }))
        )
        console.log(`âœ… Word chunks indexed to MemMachine`)
      } catch (err: any) {
        console.error('Failed to index Word to MemMachine:', err)
      }
    }

    // å¤„ç† Excel è¡¨æ ¼
    if (category === 'excel') {
      const excelData = await processExcel(filepath)
      updateData.extractedText = excelData.text
      updateData.description = `Excel è¡¨æ ¼ï¼Œ${excelData.sheets} ä¸ªå·¥ä½œè¡¨`

      const chunks = chunkText(excelData.text)
      console.log(`ğŸ“Š Excel processing complete: ${excelData.text.length} chars, ${chunks.length} chunks`)

      await Promise.all(
        chunks.map((content, index) =>
          prisma.fileChunk.create({
            data: {
              fileId: dbId,
              chunkIndex: index,
              content,
            },
          })
        )
      )

      try {
        await userMemClient.addMemories(
          chunks.map((content, index) => ({
            content: `[Excelè¡¨æ ¼: ${path.basename(filepath)} - ç¬¬${index + 1}å—]\n${content}`,
            role: 'user',
            producer: userId,
            produced_for: 'assistant',
            metadata: {
              fileId: dbId,
              chunkIndex: index.toString(),
              type: 'excel_chunk',
              filename: path.basename(filepath),
              sheets: excelData.sheets.toString(),
            },
          }))
        )
        console.log(`âœ… Excel chunks indexed to MemMachine`)
      } catch (err: any) {
        console.error('Failed to index Excel to MemMachine:', err)
      }
    }

    // å¤„ç†æ–‡æœ¬æ–‡ä»¶ (txt, md)
    if (category === 'text') {
      const textData = await processTextFile(filepath)
      updateData.extractedText = textData.text
      updateData.description = `æ–‡æœ¬æ–‡ä»¶ï¼Œ${textData.text.length} å­—ç¬¦`

      const chunks = chunkText(textData.text)
      console.log(`ğŸ“ Text processing complete: ${textData.text.length} chars, ${chunks.length} chunks`)

      await Promise.all(
        chunks.map((content, index) =>
          prisma.fileChunk.create({
            data: {
              fileId: dbId,
              chunkIndex: index,
              content,
            },
          })
        )
      )

      try {
        await userMemClient.addMemories(
          chunks.map((content, index) => ({
            content: `[æ–‡æœ¬æ–‡ä»¶: ${path.basename(filepath)} - ç¬¬${index + 1}å—]\n${content}`,
            role: 'user',
            producer: userId,
            produced_for: 'assistant',
            metadata: {
              fileId: dbId,
              chunkIndex: index.toString(),
              type: 'text_chunk',
              filename: path.basename(filepath),
            },
          }))
        )
        console.log(`âœ… Text chunks indexed to MemMachine`)
      } catch (err: any) {
        console.error('Failed to index text to MemMachine:', err)
      }
    }

    // å¤„ç† PDF
    if (category === 'pdf') {
      let pdfData;
      if (extractedText && pdfPages) {
        // ä½¿ç”¨å®¢æˆ·ç«¯æå–çš„æ–‡æœ¬
        pdfData = {
          text: extractedText,
          pages: parseInt(pdfPages) || 0
        };
        console.log(`ğŸ“„ Using client-extracted PDF text: ${extractedText.length} chars, ${pdfPages} pages`);
      } else {
        // å›é€€åˆ°æœåŠ¡ç«¯å¤„ç†ï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼‰
        pdfData = await processPDF(filepath);
        console.log(`âš ï¸  Fallback to server-side PDF extraction`);
      }

      updateData.extractedText = pdfData.text
      updateData.description = `PDF æ–‡æ¡£ï¼Œå…± ${pdfData.pages} é¡µ`

      // æ–‡æœ¬åˆ†å—
      const chunks = chunkText(pdfData.text)
      console.log(`ğŸ“„ PDF processing complete: ${pdfData.text.length} chars, ${chunks.length} chunks`)

      // ä¿å­˜åˆ†å—åˆ°æ•°æ®åº“
      await Promise.all(
        chunks.map((content, index) =>
          prisma.fileChunk.create({
            data: {
              fileId: dbId,
              chunkIndex: index,
              content,
            },
          })
        )
      )

      // ç´¢å¼•åˆ° MemMachine
      try {
        console.log(`ğŸ“¤ Indexing ${chunks.length} chunks to MemMachine...`)
        const memResult = await userMemClient.addMemories(
          chunks.map((content, index) => ({
            content: `[PDFæ–‡æ¡£: ${path.basename(filepath)} - ç¬¬${index + 1}å—]\n${content}`,
            role: 'user',  // MemMachine åªæ¥å— 'user' æˆ– 'assistant'
            producer: userId,
            produced_for: 'assistant',
            metadata: {
              fileId: dbId,
              chunkIndex: index.toString(),
              type: 'pdf_chunk',
              filename: path.basename(filepath),
            },
          }))
        )
        console.log(`âœ… PDF chunks indexed to MemMachine successfully!`)
        console.log(`   UIDs: ${memResult.results?.map(r => r.uid).join(', ') || 'N/A'}`)
      } catch (err: any) {
        console.error('âŒ CRITICAL: Failed to index PDF to MemMachine!')
        console.error('   Error:', err.message)
        console.error('   Stack:', err.stack)

        // Mark file as error to alert user about indexing failure
        await prisma.file.update({
          where: { id: dbId },
          data: {
            status: 'error',
            errorMessage: `MemMachine indexing failed: ${err.message}`,
          },
        })

        // Don't throw - file is saved but not indexed
        console.error(`âš ï¸  File saved to database but NOT indexed to MemMachine: ${fileId}`)
        return // Exit early, don't mark as 'ready'
      }
    }

    // æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
    updateData.status = 'ready'

    await prisma.file.update({
      where: { id: dbId },
      data: updateData,
    })

    console.log(`âœ… File processing completed: ${fileId}`)

  } catch (error: any) {
    console.error(`âŒ File processing failed: ${fileId}`, error)
    await prisma.file.update({
      where: { id: dbId },
      data: {
        status: 'error',
        errorMessage: error.message,
      },
    })
  }
}
